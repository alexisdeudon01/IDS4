# Architecture du pipeline SOC IDS

Ce document d√©crit l‚Äôarchitecture cible du pipeline SOC pour un IDS Suricata d√©ploy√© sur **Raspberry Pi 5 (8 GB RAM)**, avec ingestion vers **AWS OpenSearch**, orchestration Python, parall√©lisme contr√¥l√© et d√©ploiement Docker.

---

## 0) Contexte mat√©riel & contraintes

### Raspberry Pi cible

| √âl√©ment          | Valeur                       |
| ---------------- | ---------------------------- |
| Mod√®le           | Raspberry Pi 5               |
| RAM              | 8 GB                         |
| CPU              | 4 √ó Cortex-A76               |
| OS               | Debian GNU/Linux 13 (Trixie) |
| IP fixe          | **192.168.178.66**           |
| Interface r√©seau | **eth0 uniquement**          |
| Swap             | 2 GB                         |
| Stockage         | microSD 119 GB               |

### Contraintes cl√©s

* **CPU total utilis√© ‚â§ 70 %**
* **RAM totale utilis√©e ‚â§ 70 %**
* Tol√©rance aux pics de trafic (burst IDS)
* Aucun blocage r√©seau ou CPU lors des tests AWS
* Pipeline r√©silient (buffer + backpressure)

---

## 1) Biblioth√®ques n√©cessaires

### Python (`requirements.txt`)

| Biblioth√®que      | R√¥le                                    |
| ----------------- | --------------------------------------- |
| boto3             | SDK AWS (cr√©ation / gestion OpenSearch) |
| opensearch-py     | Client OpenSearch (bulk, health checks) |
| uvloop            | Boucle asyncio ultra-performante        |
| asyncio           | Parall√©lisme I/O                        |
| orjson            | S√©rialisation JSON rapide               |
| msgpack-python    | Format binaire rapide (interne)         |
| aioredis          | Buffer Redis asynchrone                 |
| PyYAML            | Parsing `config.yaml`                   |
| watchdog          | Suivi temps r√©el de `eve.json`          |
| requests          | HTTP simple                             |
| prometheus-client | Export m√©triques                        |
| GitPython         | Commit / push sur branche `dev`         |
| pytest            | Tests                                   |

---

## 2) Strat√©gie globale

Le projet repose sur une **strat√©gie ‚Äúpipeline orient√© flux‚Äù**, d√©coupl√©e, asynchrone et r√©siliente.

### Principes cl√©s

* **D√©couplage** : Suricata ‚â† Vector ‚â† OpenSearch
* **Backpressure** : Redis absorbe les pics
* **Async first** : aucun appel r√©seau bloquant
* **Configuration unique** : `config.yaml`
* **Automatisation totale** : z√©ro configuration manuelle
* **Observabilit√© native** : m√©triques partout

---

## 3) Qu‚Äôest-ce que l‚ÄôAWS SDK (boto3) ?

`boto3` est le **SDK officiel AWS pour Python**.

Il permet :

* Authentification via **SigV4**
* Appels API s√©curis√©s
* Cr√©ation / description de ressources AWS
* Polling d‚Äô√©tat non bloquant

### Utilisation dans ce projet

* Cr√©ation ou r√©cup√©ration du **OpenSearch Domain**
* Attente de l‚Äô√©tat `ACTIVE`
* R√©cup√©ration de l‚Äôendpoint
* Application d‚Äôindex templates
* Tests de connectivit√©

---

## 4) Qu‚Äôest-ce que le pipeline SOC ?

Un pipeline SOC est une **cha√Æne continue de traitement de logs s√©curit√©**.

### Cha√Æne logique

1. Capture r√©seau (Suricata)
2. √âcriture JSON (`eve.json`)
3. Parsing / mapping ECS (Vector)
4. Bufferisation (Redis)
5. Ingestion bulk (OpenSearch)
6. Visualisation / alertes
7. Monitoring syst√®me & pipeline

### Sch√©ma simplifi√©

```
Suricata ‚Üí Vector ‚Üí Redis ‚Üí OpenSearch
              ‚Üì
         Prometheus ‚Üí Grafana
```

---

## 5) Structures de donn√©es

### 5.1 Suricata JSON (eve.json)

```json
{
  "timestamp": "2026-02-01T02:10:00.123Z",
  "event_type": "alert",
  "src_ip": "192.168.178.5",
  "dest_ip": "10.0.0.10",
  "alert": {
    "signature": "ET SCAN ...",
    "severity": 2
  }
}
```

---

### 5.2 ECS (apr√®s Vector)

```json
{
  "@timestamp": "2026-02-01T02:10:00.123Z",
  "event": {
    "kind": "alert",
    "category": "network"
  },
  "source": {
    "ip": "192.168.178.5"
  },
  "destination": {
    "ip": "10.0.0.10"
  },
  "suricata": {
    "signature": "ET SCAN ...",
    "severity": 2
  }
}
```

---

### 5.3 Bulk OpenSearch (NDJSON)

```
{ "index": { "_index": "suricata-2026.02.01" } }
{ "doc ECS" }
```

---

## 6) Phases du syst√®me

### Phase A ‚Äî Initialisation Raspberry Pi

* D√©sactiver toutes les interfaces sauf `eth0`
* Configurer firewall minimal
* Cr√©er RAM disk pour logs
* Installer Docker & Python

---

### Phase B ‚Äî Provisioning AWS

* Charger `config.yaml`
* V√©rifier credentials
* Cr√©er ou d√©tecter domaine
* Attendre `ACTIVE`
* Sauvegarder endpoint

---

### Phase C ‚Äî Tests r√©seau (asynchrones)

Ex√©cut√©s **en parall√®le** :

* DNS
* TLS
* Bulk

---

### Phase D ‚Äî G√©n√©ration de configurations

* `suricata.yaml`
* `vector.toml`
* `docker-compose.yml`
* `prometheus.yml`
* Dashboards Grafana

---

### Phase E ‚Äî D√©ploiement Docker

* Redis
* Vector
* Prometheus
* Grafana

---

### Phase F ‚Äî Ingestion & monitoring

* Tail `eve.json`
* Vector ‚Üí Redis ‚Üí OpenSearch
* Export m√©triques
* Alerting

---

### Phase G ‚Äî Git (branche dev)

* V√©rification branche `dev`
* Commit automatique
* Push sur `dev`

---

## 7) Conteneurs Docker

| Conteneur  | R√¥le                |
| ---------- | ------------------- |
| Redis      | Buffer backpressure |
| Vector     | Parsing + ingestion |
| Prometheus | Collecte m√©triques  |
| Grafana    | Dashboards          |

---

## 8) Parall√©lisme & multithreading

### 8.1 Parall√©lisme Python (I/O)

Utilis√© pour :

* DNS
* TLS
* Tests bulk
* Monitoring

```python
await asyncio.gather(
  test_dns(),
  test_tls(),
  test_bulk()
)
```

### 8.2 Vector (natif)

Vector est √©crit en **Rust**, multi-thread nativement :

* Lecture fichiers
* Parsing ECS
* Batching
* Retry/backoff

---

## 9) Gestion CPU & RAM (< 70 %)

### R√©partition CPU

| Composant  | CPU     |
| ---------- | ------- |
| Suricata   | 3 c≈ìurs |
| Vector     | 1 c≈ìur  |
| Redis      | faible  |
| Prometheus | faible  |
| Grafana    | faible  |

### R√©partition RAM

| Composant    | RAM max |
| ------------ | ------- |
| Suricata     | ~4 GB   |
| Vector       | ~1 GB   |
| Redis        | ~512 MB |
| Docker stack | ~1 GB   |
| Libre        | >1 GB   |

### M√©canismes de contr√¥le

* Limites Docker (`mem_limit`, `cpus`)
* Batching Vector
* Chunking async Python
* Garbage collection Python forc√©e
* Rotation logs RAM disk

---

## 10) R√©seau & s√©curit√©

### Interface

* **eth0 uniquement**
* IP : **192.168.178.66**

```bash
ip link set wlan0 down
ip link set usb0 down
```

### Firewall minimal

```bash
iptables -A OUTPUT -o eth0 -p tcp --dport 443 -j ACCEPT
iptables -A OUTPUT -o eth0 -p udp --dport 53 -j ACCEPT
iptables -P OUTPUT DROP
iptables -P INPUT DROP
```

---

## 11) Agent SOC

Le projet inclut un **agent SOC Python** qui :

* Orchestre toutes les phases
* Surveille l‚Äô√©tat du pipeline
* Expose m√©triques Prometheus
* G√®re les retries
* Contr√¥le l‚Äôutilisation CPU/RAM
* Peut √™tre lanc√© comme **service systemd**

üëâ L‚Äôagent est le **cerveau du syst√®me**.

---

## 12) Amazon Q dans VS Code

### Pr√©requis

* Extension **AWS Toolkit / Amazon Q** install√©e
* Profil AWS d√©j√† configur√© : **`moi33`**
* Variables AWS d√©j√† pr√©sentes

### Configuration

Dans VS Code :

1. Ouvrir **AWS Toolkit**
2. S√©lectionner le profil **`moi33`**
3. V√©rifier la r√©gion (`eu-central-1`)

### Utilisation avec ce projet

Amazon Q peut :

* Expliquer le code
* G√©n√©rer des tests
* V√©rifier la config AWS
* Aider √† d√©boguer Vector / Suricata

Aucune configuration suppl√©mentaire requise.

---

## 13) R√©sum√© final

‚úî Architecture robuste
‚úî Async & multithread contr√¥l√©
‚úî Limites CPU/RAM respect√©es
‚úî Observabilit√© compl√®te
‚úî S√©curit√© r√©seau stricte
‚úî D√©ploiement reproductible
‚úî Agent SOC central
‚úî Compatible Amazon Q / VS Code
